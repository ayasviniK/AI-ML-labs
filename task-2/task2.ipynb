{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3576a859",
      "metadata": {
        "id": "3576a859"
      },
      "outputs": [],
      "source": [
        "# Sentiment Analysis for US Airlines tweets\n",
        "# Step 1: Imports and dataset load\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"crowdflower/twitter-airline-sentiment\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSlGLAKbIIJW",
        "outputId": "f01370cf-bbbc-496b-8f79-60cbea37f2cd"
      },
      "id": "DSlGLAKbIIJW",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'twitter-airline-sentiment' dataset.\n",
            "Path to dataset files: /kaggle/input/twitter-airline-sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "73c92414",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73c92414",
        "outputId": "ec7ef3fe-bdcc-4118-a5a5-f3b4a14d7b5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded dataset from '/kaggle/input/twitter-airline-sentiment/Tweets.csv'\n",
            "Dataset shape: (14640, 15)\n",
            "Columns: ['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence', 'negativereason', 'negativereason_confidence', 'airline', 'airline_sentiment_gold', 'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord', 'tweet_created', 'tweet_location', 'user_timezone']\n",
            "airline_sentiment\n",
            "negative    9178\n",
            "neutral     3099\n",
            "positive    2363\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Try to load the Kaggle dataset file 'Tweets.csv' in the current folder\n",
        "candidates = ['Tweets.csv', 'tweets.csv', 'twitter-airline-sentiment.csv', os.path.join(path, 'Tweets.csv')]\n",
        "for fn in candidates:\n",
        "    if os.path.exists(fn):\n",
        "        df = pd.read_csv(fn)\n",
        "        print(f\"Loaded dataset from '{fn}'\")\n",
        "        break\n",
        "else:\n",
        "    raise FileNotFoundError(\n",
        "        \"Dataset file not found. Please put 'Tweets.csv' in the same folder as this notebook or change the filename.\"\n",
        "    )\n",
        "\n",
        "print('Dataset shape:', df.shape)\n",
        "print('Columns:', df.columns.tolist())\n",
        "# Keep only required columns\n",
        "if 'airline_sentiment' in df.columns and 'text' in df.columns:\n",
        "    df = df[['airline_sentiment', 'text']].copy()\n",
        "else:\n",
        "    raise KeyError(\"Expected columns 'airline_sentiment' and 'text' not found in the dataset.\")\n",
        "\n",
        "# Quick class distribution\n",
        "print(df['airline_sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b4eb3cc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4eb3cc0",
        "outputId": "094bd82c-2230-4445-a02e-4e5666d78c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning texts...\n",
            "Example cleaned text:\n",
            "@VirginAmerica What @dhepburn said.\n",
            "virginamerica dhepburn said\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Preprocess text - define clean_text and apply\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab') # Add this line to download the missing resource\n",
        "\n",
        "ps = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "import string\n",
        "\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "    text = text.lower()\n",
        "    # remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
        "    # tokenize\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    cleaned = []\n",
        "    for token in tokens:\n",
        "        token = token.strip()\n",
        "        if token in stop_words:\n",
        "            continue\n",
        "        if all(ch in string.punctuation for ch in token):\n",
        "            continue\n",
        "        # stem\n",
        "        token = ps.stem(token)\n",
        "        cleaned.append(token)\n",
        "    return ' '.join(cleaned)\n",
        "\n",
        "# Apply cleaning (this may take a short time)\n",
        "print('Cleaning texts...')\n",
        "df['text_cleaned'] = df['text'].apply(clean_text)\n",
        "print('Example cleaned text:')\n",
        "print(df['text'].iloc[0])\n",
        "print(df['text_cleaned'].iloc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "44bc5f75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44bc5f75",
        "outputId": "a9c25f70-2c0d-497f-83bb-10a5a6512c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature matrix shape: (14640, 3000)\n",
            "Encoded classes: [('negative', np.int64(0)), ('neutral', np.int64(1)), ('positive', np.int64(2))]\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Feature extraction - TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=3000)\n",
        "X = vectorizer.fit_transform(df['text_cleaned']).toarray()\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(df['airline_sentiment'])\n",
        "\n",
        "print('Feature matrix shape:', X.shape)\n",
        "print('Encoded classes:', list(zip(le.classes_, le.transform(le.classes_))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5d1402d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d1402d4",
        "outputId": "ecb88bbd-7b65-4b90-f0e0-303e800597b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (11712, 3000) Test shape: (2928, 3000)\n",
            "Naive Bayes Accuracy: 0.7346311475409836\n",
            "\n",
            "Classification Report (NB):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.73      0.98      0.84      1835\n",
            "     neutral       0.70      0.27      0.39       620\n",
            "    positive       0.84      0.40      0.54       473\n",
            "\n",
            "    accuracy                           0.73      2928\n",
            "   macro avg       0.76      0.55      0.59      2928\n",
            "weighted avg       0.74      0.73      0.69      2928\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Train/test split and train Multinomial Naive Bayes\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2, stratify=Y)\n",
        "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n",
        "\n",
        "# Multinomial Naive Bayes\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "print('Naive Bayes Accuracy:', accuracy_score(y_test, y_pred_nb))\n",
        "print('\\nClassification Report (NB):')\n",
        "print(classification_report(y_test, y_pred_nb, target_names=le.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "34e8e6ad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34e8e6ad",
        "outputId": "32ef26f1-7659-4936-cbdd-9b9c6be822e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.7575136612021858\n",
            "\n",
            "Classification Report (RF):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.78      0.94      0.85      1835\n",
            "     neutral       0.66      0.38      0.48       620\n",
            "    positive       0.74      0.55      0.64       473\n",
            "\n",
            "    accuracy                           0.76      2928\n",
            "   macro avg       0.73      0.62      0.65      2928\n",
            "weighted avg       0.75      0.76      0.74      2928\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Train Random Forest classifier\n",
        "rf = RandomForestClassifier(random_state=2)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print('Random Forest Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
        "print('\\nClassification Report (RF):')\n",
        "print(classification_report(y_test, y_pred_rf, target_names=le.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0e03c22e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e03c22e",
        "outputId": "e87cf6a1-83f3-4c85-ff30-83289e6bbdae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: tfidf_vectorizer.joblib, naive_bayes_model.joblib, random_forest_model.joblib, label_encoder.joblib\n"
          ]
        }
      ],
      "source": [
        "# Step 6: Save vectorizer and models\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.joblib')\n",
        "joblib.dump(nb, 'naive_bayes_model.joblib')\n",
        "joblib.dump(rf, 'random_forest_model.joblib')\n",
        "joblib.dump(le, 'label_encoder.joblib')\n",
        "print('Saved: tfidf_vectorizer.joblib, naive_bayes_model.joblib, random_forest_model.joblib, label_encoder.joblib')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}